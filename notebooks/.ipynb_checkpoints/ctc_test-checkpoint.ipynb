{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/colaprograms/2019-hackathon-ocr-wymbah/blob/master/notebooks/ctc_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "47zAK9Hd86yi"
   },
   "outputs": [],
   "source": [
    "import os, torch, re, sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as p\n",
    "import random, PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "colab_type": "code",
    "id": "nnmS2Npz9SDs",
    "outputId": "4f1a6a8b-03e4-4088-e4ca-6e990be24540"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're in a Jupyter notebook!\n",
      "Changing directory to /home/gibson/sdb2/cola/ass/balls/2019-hackathon-ocr-wymbah\n",
      "Checkpoints are going to /home/gibson/sdb2/cola/ass/balls/2019-hackathon-ocr-wymbah/checkpoint\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "from os.path import join\n",
    "def exists(*arg):\n",
    "    return os.path.exists(join(*arg))\n",
    "def trymkdir(*arg):\n",
    "    try:\n",
    "        os.mkdir(join(*arg))\n",
    "        print(\"Created directory\", join(*arg))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "if exists(\"/content\"):\n",
    "    PATH = \"/content\"\n",
    "    print(\"We're on Google Colab!\")\n",
    "    os.chdir(PATH)\n",
    "    if not exists(PATH, \"AI4Good---Meza-OCR-Challenge\"):\n",
    "      !git clone https://github.com/Charitable-Analytics-International/AI4Good---Meza-OCR-Challenge\n",
    "    if not exists(PATH, \"2019-hackathon-ocr-wymbah\"):\n",
    "      !git clone https://github.com/colaprograms/2019-hackathon-ocr-wymbah\n",
    "    CODE_PATH = join(PATH, \"2019-hackathon-ocr-wymbah\")\n",
    "    \"The code may have changed on GitHub since we cloned it\"\n",
    "    !git pull\n",
    "    \n",
    "    \"Mount Google Drive on /content/gdrive/My Drive and try to save checkpoints in code/checkpoint\"\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/gdrive\")\n",
    "    trymkdir(\"/content/gdrive/My Drive/code\")\n",
    "    trymkdir(\"/content/gdrive/My Drive/code/checkpoint\")\n",
    "    CHECKPOINT_PATH = \"/content/gdrive/My Drive/code/checkpoint\"\n",
    "else:\n",
    "    print(\"We're in a Jupyter notebook!\")\n",
    "    if exists(\"../notebooks\"):\n",
    "        \"Move out of the notebooks directory\"\n",
    "        os.chdir(\"..\")\n",
    "    CODE_PATH = os.getcwd()\n",
    "    CHECKPOINT_PATH = join(CODE_PATH, \"checkpoint\")\n",
    "    trymkdir(CHECKPOINT_PATH)\n",
    "\n",
    "print(\"Changing directory to\", CODE_PATH)\n",
    "os.chdir(CODE_PATH)\n",
    "print(\"Checkpoints are going to\", CHECKPOINT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "# Numpy will show all numbers to 4 decimal places\n",
    "np.set_printoptions(4, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "colab_type": "code",
    "id": "RBrQBRzb9Vyp",
    "outputId": "a80f4b38-70a9-4626-ff3b-ea9ec544702d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading util.file\n",
      "Using images in ../AI4Good---Meza-OCR-Challenge\n",
      "\n",
      "Reloading util.chars\n",
      "\n",
      "Reloading nets.ctcnet\n",
      "\n",
      "Loaded 6747 training images and 750 validation images\n"
     ]
    }
   ],
   "source": [
    "# Reload all of our modules in case they changed\n",
    "\n",
    "modules_to_reload = [\n",
    "    \"util.file\",\n",
    "    \"util.chars\",\n",
    "    \"nets.ctcnet\"\n",
    "]\n",
    "\n",
    "from importlib import import_module, reload\n",
    "for module in modules_to_reload:\n",
    "    print(\"Reloading %s\" % module)\n",
    "    reload(import_module(module))\n",
    "    print()\n",
    "\n",
    "from util.chars import chars, nchars, idx, input_to_string\n",
    "from util.file import FileHolder\n",
    "from nets.ctcnet import CTCModel\n",
    "\n",
    "fh = FileHolder()\n",
    "print(\"Loaded %d training images and %d validation images\" %\n",
    "     (fh.ntraining(), fh.nvalidation()))\n",
    "\n",
    "print()\n",
    "print(\"Showing an example image\")\n",
    "b = fh.get_batch_tensor(1)\n",
    "b = b[0].numpy().squeeze().transpose(1, 2, 0)\n",
    "p.imshow(b)\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 21013
    },
    "colab_type": "code",
    "id": "gj9U2jENAnfQ",
    "outputId": "b37ed1e6-651d-47d6-e20d-d087c2faf184",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Loss: 11.403440\n",
      "Validation loss: 8.130249\n",
      "Saved checkpoint/checkpoint-0000-8.13\n",
      "Epoch 1. Loss: 7.784208\n",
      "Validation loss: 7.298856\n",
      "Saved checkpoint/checkpoint-0001-7.30\n",
      "Epoch 2. Loss: 6.659159\n",
      "Validation loss: 6.001410\n",
      "Saved checkpoint/checkpoint-0002-6.00\n",
      "Epoch 3. Loss: 5.313880\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "class Runner:\n",
    "    def __init__(self):\n",
    "        self.model = CTCModel().cuda()\n",
    "        self.loss = nn.CTCLoss(reduction='sum').cuda()\n",
    "        self.optimizer = optim.SGD(\n",
    "            self.model.parameters(),\n",
    "            lr = 0.0001, # It gets pretty unstable with larger lrs.\n",
    "            momentum = 0.9,\n",
    "            nesterov = True, # Everyone loves Nesterov\n",
    "            weight_decay = 0.001 # A little bit of regularization\n",
    "        )\n",
    "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer,\n",
    "            patience=6,\n",
    "            verbose=True\n",
    "        )\n",
    "        self.trainloss = []\n",
    "        self.validloss = []\n",
    "        \n",
    "    def predict(self, inputs):\n",
    "        # Enter evaluation mode\n",
    "        self.model.eval()\n",
    "        return self.model(inputs.clone().cuda())\n",
    "    \n",
    "    def one_batch_loss(self, inputs, outputs):\n",
    "        inputs = self.model(inputs.clone().cuda())\n",
    "        inputs = inputs.permute(1, 0, 2)\n",
    "        # sequence, batch, channels\n",
    "        # All sequences should be 32 long, because that's\n",
    "        # the size of the image after we pad to 256 pixels\n",
    "        # and then run it through the convolutions.\n",
    "        assert inputs.shape[0] == 32\n",
    "        input_lengths = torch.tensor(\n",
    "            [32 for i in range(inputs.shape[1])],\n",
    "            dtype=torch.int32\n",
    "        )\n",
    "        target, target_lengths = Runner.maketarget(outputs)\n",
    "        \n",
    "        loss = self.loss(inputs, target, input_lengths, target_lengths)\n",
    "        return loss\n",
    "    \n",
    "    @staticmethod\n",
    "    def maketarget(outputs):\n",
    "        classes = []\n",
    "        \"Concatenate all the outputs into one array\"\n",
    "        for string in outputs:\n",
    "            classes.extend([idx[c] for c in string])\n",
    "        lengths = [len(string) for string in outputs]\n",
    "        # We use int32 because Torch promises us that we\n",
    "        # can use special CuDNN code if we meet some\n",
    "        # requirements, and one of the requirements is\n",
    "        # that these tensors have type torch.int32.\n",
    "        return (\n",
    "            torch.tensor(classes, dtype=torch.int32),\n",
    "            torch.tensor(lengths, dtype=torch.int32)\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def logits_to_string(logits):\n",
    "        assert logits.shape[0] == 1\n",
    "        length = logits.shape[1]\n",
    "        if isinstance(logits, torch.Tensor):\n",
    "            logits = logits.clone().detach().cpu().numpy()\n",
    "        def randchoice(p):\n",
    "            p = np.exp(p)\n",
    "            if np.abs(np.sum(p) - 1) > 1e-6:\n",
    "                raise Exception(\"logits are not properly normalized\")\n",
    "            u = random.random()\n",
    "            for i in range(p.shape[0]):\n",
    "                u -= p[i]\n",
    "                if u < 1e-6:\n",
    "                    return i\n",
    "        def characterat(j):\n",
    "            return chars[randchoice(logits[0, j, :])]\n",
    "        return \"\".join(characterat(j) for j in range(length))\n",
    "    \n",
    "    def __train(self, epoch):\n",
    "        # set training mode just in case it has somehow been unset\n",
    "        self.model.train()\n",
    "        running_loss = 0.0\n",
    "        length = 0\n",
    "        #print(\"Example output:\")\n",
    "        for i in range(100):\n",
    "          inputs, outputs = fh.get_batch_tensor(BATCH_SIZE)\n",
    "          self.optimizer.zero_grad()\n",
    "          loss = self.one_batch_loss(inputs, outputs)\n",
    "          loss.backward()\n",
    "          self.optimizer.step()\n",
    "          running_loss += loss.item()\n",
    "          length += BATCH_SIZE\n",
    "        loss = None\n",
    "        trainingloss = running_loss / length\n",
    "        print(\"Epoch %d. Loss: %f\" % (epoch, trainingloss))\n",
    "        self.trainloss.append(trainingloss)\n",
    "    \n",
    "    def __valid(self, epoch):\n",
    "        running_loss = 0.0\n",
    "        length = 0\n",
    "        with torch.no_grad():\n",
    "            for i in range(100):\n",
    "                inputs, outputs = fh.get_batch_tensor(BATCH_SIZE, validation=True)\n",
    "                loss = self.one_batch_loss(inputs, outputs)\n",
    "                running_loss += loss.item()\n",
    "                length += BATCH_SIZE\n",
    "        validationloss = running_loss / length\n",
    "        self.scheduler.step(validationloss)\n",
    "        print(\"Validation loss: %f\" % validationloss)\n",
    "        self.validloss.append(validationloss)\n",
    "        file = \"checkpoint/checkpoint-%04d-%.2f\" % (epoch, validationloss)\n",
    "        torch.save({\n",
    "            'model': self.model.state_dict(),\n",
    "            'trainloss': self.trainloss,\n",
    "            'validloss': self.validloss\n",
    "        }, file)\n",
    "        print(\"Saved\", file)\n",
    "    \n",
    "    def load_from(self, file):\n",
    "        checkpoint = torch.load(file)\n",
    "        self.model.load_state_dict(checkpoint['model'])\n",
    "        self.trainloss, self.validloss = checkpoint['trainloss'], checkpoint['validloss']\n",
    "        \n",
    "    def run(self, epochs, resume_checkpoint=None):\n",
    "        if resume_checkpoint is None:\n",
    "            print(\"Training network from scratch\")\n",
    "        else:\n",
    "            self.load_from(resume_checkpoint)\n",
    "        for epoch in range(epochs):\n",
    "            self.__train(epoch)\n",
    "            self.__valid(epoch)\n",
    "\n",
    "blade = Runner()\n",
    "blade.run(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7KXbhC7NAoZF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hj5J3EU6Bkod"
   },
   "outputs": [],
   "source": [
    "image_tensor = torch.Tensor(image)\n",
    "image_tensor = torch.unsqueeze(image_tensor, 0)\n",
    "image_tensor = image_tensor.permute(0, 3, 1, 2)\n",
    "out = resnet(image_tensor)\n",
    "print(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VzT9wrddCOmt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7PxeqSiVE8pH"
   },
   "outputs": [],
   "source": [
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "'\n",
    "7878787878787878787878787878787878787878787878787878787878787878787878787878787878787878787878787878787878787878787878787878787878787878787878787878787878787878[pppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppmjnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx]'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "ctc-test.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
