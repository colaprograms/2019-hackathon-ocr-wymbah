{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ctc-test.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/colaprograms/2019-hackathon-ocr-wymbah/blob/master/notebooks/ctc_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47zAK9Hd86yi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, torch, re, sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as p\n",
        "import random, PIL"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnmS2Npz9SDs",
        "colab_type": "code",
        "outputId": "72b64a64-2cb8-407a-b03a-2352bc3efe31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "source": [
        "os.chdir(\"/content\")\n",
        "if not os.path.exists(\"/content/AI4Good---Meza-OCR-Challenge\"):\n",
        "  !git clone https://github.com/Charitable-Analytics-International/AI4Good---Meza-OCR-Challenge\n",
        "if not os.path.exists(\"/content/2019-hackathon-ocr-wymbah\"):\n",
        "  !git clone https://github.com/colaprograms/2019-hackathon-ocr-wymbah\n",
        "os.chdir(\"/content/2019-hackathon-ocr-wymbah\")\n",
        "!git pull\n",
        "\n",
        "from importlib import reload\n",
        "import util.file\n",
        "reload(util.file)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "try:\n",
        "  os.mkdir(\"/content/gdrive/My Drive/code\")\n",
        "except:\n",
        "  pass\n",
        "try:\n",
        "  os.mkdir(\"/content/gdrive/My Drive/code/checkpoint\")\n",
        "except:\n",
        "  pass"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 23, done.\u001b[K\n",
            "remote: Counting objects:   4% (1/23)   \u001b[K\rremote: Counting objects:   8% (2/23)   \u001b[K\rremote: Counting objects:  13% (3/23)   \u001b[K\rremote: Counting objects:  17% (4/23)   \u001b[K\rremote: Counting objects:  21% (5/23)   \u001b[K\rremote: Counting objects:  26% (6/23)   \u001b[K\rremote: Counting objects:  30% (7/23)   \u001b[K\rremote: Counting objects:  34% (8/23)   \u001b[K\rremote: Counting objects:  39% (9/23)   \u001b[K\rremote: Counting objects:  43% (10/23)   \u001b[K\rremote: Counting objects:  47% (11/23)   \u001b[K\rremote: Counting objects:  52% (12/23)   \u001b[K\rremote: Counting objects:  56% (13/23)   \u001b[K\rremote: Counting objects:  60% (14/23)   \u001b[K\rremote: Counting objects:  65% (15/23)   \u001b[K\rremote: Counting objects:  69% (16/23)   \u001b[K\rremote: Counting objects:  73% (17/23)   \u001b[K\rremote: Counting objects:  78% (18/23)   \u001b[K\rremote: Counting objects:  82% (19/23)   \u001b[K\rremote: Counting objects:  86% (20/23)   \u001b[K\rremote: Counting objects:  91% (21/23)   \u001b[K\rremote: Counting objects:  95% (22/23)   \u001b[K\rremote: Counting objects: 100% (23/23)   \u001b[K\rremote: Counting objects: 100% (23/23), done.\u001b[K\n",
            "remote: Compressing objects:   7% (1/13)   \u001b[K\rremote: Compressing objects:  15% (2/13)   \u001b[K\rremote: Compressing objects:  23% (3/13)   \u001b[K\rremote: Compressing objects:  30% (4/13)   \u001b[K\rremote: Compressing objects:  38% (5/13)   \u001b[K\rremote: Compressing objects:  46% (6/13)   \u001b[K\rremote: Compressing objects:  53% (7/13)   \u001b[K\rremote: Compressing objects:  61% (8/13)   \u001b[K\rremote: Compressing objects:  69% (9/13)   \u001b[K\rremote: Compressing objects:  76% (10/13)   \u001b[K\rremote: Compressing objects:  84% (11/13)   \u001b[K\rremote: Compressing objects:  92% (12/13)   \u001b[K\rremote: Compressing objects: 100% (13/13)   \u001b[K\rremote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "Unpacking objects:   5% (1/18)   \rUnpacking objects:  11% (2/18)   \rUnpacking objects:  16% (3/18)   \rUnpacking objects:  22% (4/18)   \rUnpacking objects:  27% (5/18)   \rUnpacking objects:  33% (6/18)   \rUnpacking objects:  38% (7/18)   \rUnpacking objects:  44% (8/18)   \rUnpacking objects:  50% (9/18)   \rUnpacking objects:  55% (10/18)   \rUnpacking objects:  61% (11/18)   \rremote: Total 18 (delta 7), reused 5 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects:  66% (12/18)   \rUnpacking objects:  72% (13/18)   \rUnpacking objects:  77% (14/18)   \rUnpacking objects:  83% (15/18)   \rUnpacking objects:  88% (16/18)   \rUnpacking objects:  94% (17/18)   \rUnpacking objects: 100% (18/18)   \rUnpacking objects: 100% (18/18), done.\n",
            "From https://github.com/colaprograms/2019-hackathon-ocr-wymbah\n",
            "   680e840..3199be8  master     -> origin/master\n",
            "Updating 680e840..3199be8\n",
            "Fast-forward\n",
            " notebooks/ctc_test.ipynb | 204 \u001b[32m++++++++++++\u001b[m\u001b[31m-----------------------------------\u001b[m\n",
            " util/file.py             |   2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 2 files changed, 51 insertions(+), 155 deletions(-)\n",
            "Using path /content/AI4Good---Meza-OCR-Challenge\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBrQBRzb9Vyp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from util.file import FileHolder\n",
        "fh = FileHolder()\n",
        "inp, outp = fh.get_batch(1)\n",
        "\n",
        "for file, val in zip(inp, outp):\n",
        "  print(val)\n",
        "  p.imshow(file)\n",
        "  p.show()\n",
        "\n",
        "def to_tensor(buf):\n",
        "  buf -= 0.5\n",
        "  buf *= 2\n",
        "  #buf -= np.mean(buf, axis=(0, 1, 2))[None, None, None, :]\n",
        "  #buf /= np.std(buf, axis=(0, 1, 2))[None, None, None, :]\n",
        "  #buf -= np.array([0.485, 0.456, 0.406])[None, None, None, :]\n",
        "  #buf /= np.array([0.229, 0.224, 0.225])[None, None, None, :]\n",
        "  return torch.tensor(buf, dtype=torch.float32).permute(0, 3, 1, 2)\n",
        "\n",
        "def get_batch(batchsize, validation=False):\n",
        "  inp, outp = fh.get_batch(batchsize, validation)\n",
        "  inp = np.stack(inp)\n",
        "  inp = to_tensor(inp)\n",
        "  return inp, outp\n",
        "\n",
        "b = get_batch(1)[0].numpy().squeeze().transpose(1, 2, 0)\n",
        "#print(np.min(b), np.max(b), np.mean(b), np.std(b))\n",
        "p.imshow(get_batch(1)[0].numpy().squeeze().transpose(1, 2, 0) * 0.5 + 0.5)\n",
        "p.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLBd53Ar990X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gj9U2jENAnfQ",
        "colab_type": "code",
        "outputId": "7f8122ba-bf50-4af8-9b99-4ca8e566e4f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1348
        }
      },
      "source": [
        "chars = \" 0123456789-,.\"\n",
        "nchars = len(chars)\n",
        "idx = {}\n",
        "for i, c in enumerate(chars): idx[c] = i\n",
        "\n",
        "ntraining = len(fh.info['training'])\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "def maketarget(outputs):\n",
        "  classes = []\n",
        "  for string in outputs:\n",
        "    classes.extend([idx[c] for c in string])\n",
        "    lengths = [len(string) for string in outputs]\n",
        "  return torch.tensor(classes, dtype=torch.long), lengths\n",
        "\n",
        "trainloss = []\n",
        "validloss = []\n",
        "class CTCModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CTCModel, self).__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "      nn.Conv2d(3, 64, (3, 3), padding=1),\n",
        "      nn.BatchNorm2d(64),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(64, 64, (3, 3), stride=2, padding=1),\n",
        "      nn.BatchNorm2d(64),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(64, 64, (3, 3), padding=1),\n",
        "      nn.BatchNorm2d(64),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(64, 128, (3, 3), stride=2, padding=1),\n",
        "      nn.BatchNorm2d(128),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(128, 128, (3, 1), padding=(1, 0)),\n",
        "      nn.BatchNorm2d(128),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(128, 128, (3, 1), stride=2, padding=(1, 0)),\n",
        "      nn.BatchNorm2d(128),\n",
        "      nn.ReLU(),\n",
        "    )\n",
        "    self.lstm1 = nn.LSTM(128, 256, batch_first=True, bidirectional=True)\n",
        "    self.layernorm1 = nn.LayerNorm((512,))\n",
        "    self.dense1 = nn.Sequential(\n",
        "        nn.Linear(512, 256, bias=False),\n",
        "        nn.BatchNorm(256),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "    self.dense2 = nn.Sequential(\n",
        "        nn.Linear(256, 256, bias=False),\n",
        "        nn.BatchNorm(256),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "    self.dense3 = nn.Sequential(\n",
        "        nn.Linear(256, nchars, bias=False),\n",
        "        nn.BatchNorm(nchars),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "    self.avgpool = nn.AdaptiveAvgPool2d((1, 32)).cuda()\n",
        "  \n",
        "  def forward(self, z):\n",
        "    z = self.conv(z)\n",
        "    z = self.avgpool(z)\n",
        "    z = z.squeeze(2).permute(0, 2, 1)\n",
        "    # batch, seq, channels\n",
        "    z, _ = self.lstm1(z)\n",
        "    z = self.layernorm1(z)\n",
        "    z = self.dense1(z)\n",
        "    z = self.dense2(z)\n",
        "    z = self.dense3(z)\n",
        "    print(z[:, 0, 0])\n",
        "    z = nn.functional.log_softmax(z, dim=2)\n",
        "    return z\n",
        "def run():\n",
        "  \"\"\"resnet = torchvision.models.resnet.resnet34(True)\n",
        "\n",
        "  \"Cut off the last two layers\"\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.maxpool(x)\n",
        "\n",
        "    x = self.layer1(x)\n",
        "    x = self.layer2(x)\n",
        "    x = self.layer3(x)\n",
        "    #x = self.layer4(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "  import types\n",
        "  resnet.forward = types.MethodType(forward, resnet)\n",
        "  resnet = resnet.cuda()\n",
        "  for param in resnet.parameters():\n",
        "    param.requires_grad = False\n",
        "  \"\"\"\n",
        "  ctcmodel = CTCModel().cuda()\n",
        "  ctc = nn.CTCLoss(reduction='sum').cuda()\n",
        "  optimizer = optim.SGD(ctcmodel.parameters(), lr=0.001, momentum=0.2, nesterov=True, weight_decay=.001)\n",
        "\n",
        "  def input_to_string(inp):\n",
        "    assert inp.shape[0] == 1\n",
        "    inp = inp.detach().cpu().numpy()\n",
        "    def randchoice(p):\n",
        "      p = np.exp(p)\n",
        "      u = random.random()\n",
        "      for i in range(p.shape[0]):\n",
        "        u -= p[i]\n",
        "        if u < 1e-6:\n",
        "          return i\n",
        "      raise Exception(\"not a probability distribution\")\n",
        "    return \"\".join(chars[randchoice(inp[0, j, :])] for j in range(inp.shape[1]))\n",
        "  def crunch(inp, outp):\n",
        "    inp = ctcmodel(inp.cuda())\n",
        "    inp = inp.permute(1, 0, 2)\n",
        "    assert inp.shape[0] == 32\n",
        "    input_lengths = [32 for i in range(inp.shape[1])]\n",
        "    target, target_lengths = maketarget(outp)\n",
        "    input_lengths, target_lengths = map(tuple, [input_lengths, target_lengths])\n",
        "    cu = target.data.cuda()\n",
        "    #print(inp)\n",
        "    loss = ctc(inp, cu, input_lengths, target_lengths)\n",
        "    return loss\n",
        "  for epoch in range(999999):\n",
        "    running_loss = 0.0\n",
        "    length = 0\n",
        "    print(\"Example output:\")\n",
        "    inp, outp = get_batch(1)\n",
        "    with torch.no_grad():\n",
        "      string = input_to_string(ctcmodel(inp.cuda()))\n",
        "    print(string, outp)\n",
        "    for i in range(160):\n",
        "      inp, outp = get_batch(BATCH_SIZE)\n",
        "      optimizer.zero_grad()\n",
        "      loss = crunch(inp, outp)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      running_loss += loss.item()\n",
        "      length += BATCH_SIZE\n",
        "    loss = None\n",
        "    trainingloss = running_loss / length\n",
        "    print(\"Epoch %d. Loss: %f\" % (epoch, trainingloss))\n",
        "    trainloss.append(trainingloss)\n",
        "    running_loss = 0.0\n",
        "    length = 0\n",
        "    with torch.no_grad():\n",
        "      for i in range(20):\n",
        "        inp, outp = get_batch(BATCH_SIZE, validation=True)\n",
        "        loss = crunch(inp, outp)\n",
        "        running_loss += loss.item()\n",
        "        length += BATCH_SIZE\n",
        "    validationloss = running_loss / length\n",
        "    print(\"Validation loss: %f\" % validationloss)\n",
        "    validloss.append(validationloss)\n",
        "    file = \"/content/gdrive/My Drive/code/checkpoint/checkpoint-%04d-%.2f\" % (epoch, validationloss)\n",
        "    torch.save({\n",
        "        'ctcmodel': ctcmodel.state_dict(),\n",
        "        'trainloss': trainloss,\n",
        "        'validloss': validloss\n",
        "    }, file)\n",
        "    print(\"Saved\", file)\n",
        "\n",
        "run()"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Example output:\n",
            "tensor([0.0365], device='cuda:0')\n",
            ".5489 8256-680--53-8407288028.65 ['95']\n",
            "tensor([0.0506, 0.0502, 0.0539, 0.0501, 0.0501, 0.0503, 0.0502, 0.0502, 0.0502,\n",
            "        0.0549, 0.0548, 0.0501, 0.0510, 0.0502, 0.0501, 0.0566, 0.0627, 0.0504,\n",
            "        0.0503, 0.0558, 0.0466, 0.0501, 0.0510, 0.0499, 0.0502, 0.0501, 0.0504,\n",
            "        0.0515, 0.0600, 0.0502, 0.0501, 0.0502, 0.0332, 0.0503, 0.0501, 0.0502,\n",
            "        0.0502, 0.0501, 0.0504, 0.0527, 0.0502, 0.0502, 0.0507, 0.0560, 0.0511,\n",
            "        0.0347, 0.0501, 0.0499, 0.0224, 0.0519, 0.0534, 0.0502, 0.0552, 0.0502,\n",
            "        0.0502, 0.0369, 0.0502, 0.0504, 0.0501, 0.0511, 0.0502, 0.0502, 0.0502,\n",
            "        0.0502], device='cuda:0', grad_fn=<SelectBackward>)\n",
            "tensor([37.0511, 37.0924, 37.0725, 37.0977, 37.0862, 37.0933, 37.0897, 37.0927,\n",
            "        37.0934, 37.0972, 37.0857, 37.0905, 37.0894, 37.0930, 37.0783, 37.0727,\n",
            "        37.0285, 37.5295, 37.0863, 37.1146, 37.0854, 37.0933, 37.0935, 37.0895,\n",
            "        37.0931, 37.0884, 37.0896, 37.0438, 37.0872, 37.0906, 37.0910, 37.0790,\n",
            "        37.0935, 37.0886, 37.0933, 37.0819, 37.0844, 37.0933, 37.0594, 37.0930,\n",
            "        37.0937, 37.1015, 37.0918, 37.0718, 37.0594, 36.9232, 38.4642, 37.0689,\n",
            "        37.0587, 37.0911, 37.0931, 37.0632, 37.0916, 37.0931, 37.0027, 37.0928,\n",
            "        37.0796, 37.0812, 37.0905, 37.0853, 37.0865, 37.0534, 37.0881, 37.0921],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "tensor([26.2355, 26.2394, 26.2407, 26.2333, 26.2392, 26.2394, 26.2393, 26.2192,\n",
            "        26.2360, 26.2360, 26.2341, 26.2337, 26.2394, 26.2383, 26.2394, 26.2394,\n",
            "        26.2394, 26.2389, 26.2388, 26.2388, 26.2154, 26.2390, 26.2380, 26.2374,\n",
            "        26.2390, 26.2379, 26.2366, 26.2382, 26.2347, 26.2394, 26.2396, 26.2394,\n",
            "        26.2394, 26.2387, 26.2394, 26.2392, 26.2390, 26.1284, 26.2382, 26.2394,\n",
            "        26.2394, 26.1338, 26.2393, 26.2392, 26.2386, 26.2392, 26.2116, 26.2394,\n",
            "        26.2394, 26.2319, 26.2305, 26.2302, 26.2393, 26.2383, 26.2394, 26.2392,\n",
            "        26.2418, 26.2394, 26.2393, 26.2251, 26.2392, 26.2278, 26.2222, 26.2330],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "tensor([82098.7422, 82096.3125, 82097.7656, 82097.2969, 82096.8125, 82097.3047,\n",
            "        82081.9375, 82097.6484, 82091.7266, 82098.1172, 82098.9453, 82095.9844,\n",
            "        82096.9297, 82098.0234, 82096.8203, 82094.4844, 82098.2344, 82098.1094,\n",
            "        82097.9297, 82097.0469, 82097.2109, 82097.7188, 82095.8594, 82094.7422,\n",
            "        82097.2578, 82097.6875, 82098.8750, 82098.0859, 82095.2500, 82099.3594,\n",
            "        82096.3516, 82097.5859, 82097.7656, 82096.7266, 82091.3828, 82098.2109,\n",
            "        82092.9531, 82089.3125, 82099.3047, 82093.6797, 82095.5156, 82097.1328,\n",
            "        82096.4844, 82094.7422, 82083.7734, 82098.1172, 82097.4922, 82096.6797,\n",
            "        82097.5391, 82098.0859, 82097.9844, 82095.8359, 82097.8828, 82098.2812,\n",
            "        82089.5547, 82089.2031, 82097.2656, 82092.1875, 82098.0703, 82097.6094,\n",
            "        82097.1406, 82093.4297, 82097.8594, 82098.0703], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
            "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-170-f3d035732490>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Saved\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-170-f3d035732490>\u001b[0m in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    133\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m       \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m       \u001b[0mlength\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KXbhC7NAoZF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hj5J3EU6Bkod",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_tensor = torch.Tensor(image)\n",
        "image_tensor = torch.unsqueeze(image_tensor, 0)\n",
        "image_tensor = image_tensor.permute(0, 3, 1, 2)\n",
        "out = resnet(image_tensor)\n",
        "print(out)\n",
        "print(out.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzT9wrddCOmt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PxeqSiVE8pH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "'\n",
        "7878787878787878787878787878787878787878787878787878787878787878787878787878787878787878787878787878787878787878787878787878787878787878787878787878787878787878[pppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppmjnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx]'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}