{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ctc-test.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/colaprograms/2019-hackathon-ocr-wymbah/blob/master/notebooks/ctc_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47zAK9Hd86yi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, torch, re, sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as p\n",
        "import random, PIL"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnmS2Npz9SDs",
        "colab_type": "code",
        "outputId": "3307362e-90c6-4135-ae1b-74add55f7f4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "os.chdir(\"/content\")\n",
        "if not os.path.exists(\"/content/AI4Good---Meza-OCR-Challenge\"):\n",
        "  !git clone https://github.com/Charitable-Analytics-International/AI4Good---Meza-OCR-Challenge\n",
        "if not os.path.exists(\"/content/2019-hackathon-ocr-wymbah\"):\n",
        "  !git clone https://github.com/colaprograms/2019-hackathon-ocr-wymbah\n",
        "os.chdir(\"/content/2019-hackathon-ocr-wymbah\")\n",
        "!git pull\n",
        "\n",
        "from importlib import reload\n",
        "import util.file\n",
        "reload(util.file)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already up to date.\n",
            "Using path /content/AI4Good---Meza-OCR-Challenge\n",
            "Using path /content/AI4Good---Meza-OCR-Challenge\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'util.file' from '/content/2019-hackathon-ocr-wymbah/util/file.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBrQBRzb9Vyp",
        "colab_type": "code",
        "outputId": "7fbcd7d9-d248-4d19-9bf6-49055e14c806",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        }
      },
      "source": [
        "from util.file import FileHolder\n",
        "fh = FileHolder()\n",
        "inp, outp = fh.get_batch(1)\n",
        "\n",
        "for file, val in zip(inp, outp):\n",
        "  print(val)\n",
        "  p.imshow(file)\n",
        "  p.show()\n",
        "\n",
        "def to_tensor(buf):\n",
        "  buf = 2*buf - 1\n",
        "  return torch.tensor(buf, dtype=torch.float32).permute(0, 3, 1, 2)\n",
        "\n",
        "def get_batch(batchsize, validation=False):\n",
        "  inp, outp = fh.get_batch(batchsize, validation)\n",
        "  inp = np.stack(inp)\n",
        "  inp = to_tensor(inp)\n",
        "  return inp, outp\n",
        "\n",
        "get_batch(20)[0].shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9,700\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAB2CAYAAADGFVhfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([20, 3, 128, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLBd53Ar990X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gj9U2jENAnfQ",
        "colab_type": "code",
        "outputId": "76ea443f-fb9c-4331-f295-997015a2e779",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        }
      },
      "source": [
        "chars = \" 0123456789-,.\"\n",
        "nchars = len(chars)\n",
        "idx = {}\n",
        "for i, c in enumerate(chars): idx[c] = i\n",
        "\n",
        "ntraining = len(fh.info['training'])\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "def maketarget(outputs):\n",
        "  classes = [torch.tensor([idx[c] for c in string], dtype=torch.long) for string in outputs]\n",
        "  lengths = [len(string) for string in outputs]\n",
        "  return nn.utils.rnn.pack_sequence(classes, enforce_sorted=False), lengths\n",
        "\n",
        "trainloss = []\n",
        "validloss = []\n",
        "def run():\n",
        "  resnet = torchvision.models.resnet.resnet34(True)\n",
        "\n",
        "  \"Cut off the last two layers\"\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.maxpool(x)\n",
        "\n",
        "    x = self.layer1(x)\n",
        "    x = self.layer2(x)\n",
        "    x = self.layer3(x)\n",
        "    x = self.layer4(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "  import types\n",
        "  resnet.forward = types.MethodType(forward, resnet)\n",
        "  resnet = resnet.cuda()\n",
        "  for param in resnet.parameters():\n",
        "    param.requires_grad = False\n",
        "  lstm = nn.LSTM(512, 128, dropout=0.1, bidirectional=True).cuda()\n",
        "  layernorm1 = nn.LayerNorm((256,)).cuda()\n",
        "  dense1 = nn.Linear(256, 256).cuda()\n",
        "  layernorm2 = nn.LayerNorm((256,)).cuda()\n",
        "  dense2 = nn.Linear(256, nchars).cuda()\n",
        "  def params():\n",
        "    yield from lstm.parameters()\n",
        "    yield from dense1.parameters()\n",
        "    yield from dense2.parameters()\n",
        "  avgpool = nn.AdaptiveAvgPool2d((1, 16)).cuda()\n",
        "  ctc = nn.CTCLoss(reduction='none').cuda()\n",
        "  \n",
        "  optimizer = optim.SGD(params(), lr=0.001, momentum=0.9)\n",
        "\n",
        "  def crunch(inp, outp):\n",
        "    inp = resnet(inp.cuda())\n",
        "    inp = avgpool(inp)\n",
        "    inp = inp.reshape([-1, 512, 16]).permute(0, 2, 1)\n",
        "    inp, _ = lstm(inp)\n",
        "    inp = layernorm1(inp)\n",
        "    inp = dense1(inp)\n",
        "    inp = layernorm2(inp)\n",
        "    inp = dense2(inp)\n",
        "    inp = nn.functional.log_softmax(inp, dim=2)\n",
        "    input_lengths = [16 for i in range(inp.shape[0])]\n",
        "    target, target_lengths = maketarget(outp)\n",
        "    input_lengths, target_lengths = map(tuple, [input_lengths, target_lengths])\n",
        "    loss = ctc(inp, target.data.cuda(), input_lengths, target_lengths)\n",
        "    return loss.mean()\n",
        "  for epoch in range(999999):\n",
        "    running_loss = 0.0\n",
        "    length = 0\n",
        "    for i in range(200):\n",
        "      inp, outp = get_batch(BATCH_SIZE)\n",
        "      optimizer.zero_grad()\n",
        "      loss = crunch(inp, outp)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      running_loss += loss.item()\n",
        "      length += BATCH_SIZE\n",
        "    trainingloss = running_loss / length\n",
        "    print(\"Epoch %d. Loss: %f\" % (epoch, trainingloss))\n",
        "    trainloss.append(trainingloss)\n",
        "    running_loss = 0.0\n",
        "    length = 0\n",
        "    for i in range(20):\n",
        "      inp, outp = get_batch(BATCH_SIZE, validation=True)\n",
        "      loss = crunch(inp, outp)\n",
        "      running_loss += loss.item()\n",
        "      length += BATCH_SIZE\n",
        "    validationloss = running_loss / length\n",
        "    print(\"Validation loss: %f\" % validationloss)\n",
        "    validloss.append(validationloss)\n",
        "    file = \"checkpoint-%04d-%.2f\" % (epoch, validationloss)\n",
        "    torch.save({\n",
        "        'lstm': lstm.state_dict(),\n",
        "        'dense1': dense1.state_dict(),\n",
        "        'dense2': dense2.state_dict(),\n",
        "        'epoch': epoch\n",
        "    }, file)\n",
        "    print(\"Saved\", file)\n",
        "\n",
        "run()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:54: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0. Loss: 0.544250\n",
            "Validation loss: 0.501702\n",
            "Saved checkpoint-0000-0.50\n",
            "Epoch 1. Loss: 0.503433\n",
            "Validation loss: 0.493178\n",
            "Saved checkpoint-0001-0.49\n",
            "Epoch 2. Loss: 0.493248\n",
            "Validation loss: 0.497423\n",
            "Saved checkpoint-0002-0.50\n",
            "Epoch 3. Loss: 0.498054\n",
            "Validation loss: 0.526267\n",
            "Saved checkpoint-0003-0.53\n",
            "Epoch 4. Loss: 0.498963\n",
            "Validation loss: 0.482861\n",
            "Saved checkpoint-0004-0.48\n",
            "Epoch 5. Loss: 0.493591\n",
            "Validation loss: 0.521288\n",
            "Saved checkpoint-0005-0.52\n",
            "Epoch 6. Loss: 0.490283\n",
            "Validation loss: 0.494549\n",
            "Saved checkpoint-0006-0.49\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-639b2cf6588f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Saved\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-43-639b2cf6588f>\u001b[0m in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m       \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-5ff00ff46819>\u001b[0m in \u001b[0;36mget_batch\u001b[0;34m(batchsize, validation)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m   \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m   \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/2019-hackathon-ocr-wymbah/util/file.py\u001b[0m in \u001b[0;36mget_batch\u001b[0;34m(self, m, validation)\u001b[0m\n\u001b[1;32m    106\u001b[0m       \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m       \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabeled_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m       \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KXbhC7NAoZF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hj5J3EU6Bkod",
        "colab_type": "code",
        "outputId": "4c8d2fe6-3c70-4aef-fcf6-7e2aebca02c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        }
      },
      "source": [
        "image_tensor = torch.Tensor(image)\n",
        "image_tensor = torch.unsqueeze(image_tensor, 0)\n",
        "image_tensor = image_tensor.permute(0, 3, 1, 2)\n",
        "out = resnet(image_tensor)\n",
        "print(out)\n",
        "print(out.shape)"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[[0.0000e+00, 8.4632e-03, 4.4118e-01,  ..., 3.5947e-01,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [1.5710e+00, 1.6492e+00, 4.3799e-01,  ..., 1.9591e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.5652e+00,\n",
            "           1.0369e-01, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 2.7234e-01,  ..., 4.7540e+00,\n",
            "           1.5719e+00, 0.0000e+00]],\n",
            "\n",
            "         [[8.1148e-01, 6.8881e-01, 1.4770e+00,  ..., 2.5300e+00,\n",
            "           2.8111e-01, 0.0000e+00],\n",
            "          [0.0000e+00, 1.1480e-01, 1.6761e+00,  ..., 3.0082e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 3.6867e-01,  ..., 6.7188e-02,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 7.3576e-01,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00]],\n",
            "\n",
            "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.6493e-01,\n",
            "           6.6963e-01, 1.3038e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 2.3498e-01,  ..., 3.9726e+00,\n",
            "           3.6936e+00, 4.9995e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.2699e+00,\n",
            "           1.9825e+00, 3.4142e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.0000e+00, 0.0000e+00, 8.0649e-01,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 1.9799e-01,  ..., 1.9203e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [8.3722e-01, 6.5913e-01, 0.0000e+00,  ..., 3.8010e+00,\n",
            "           8.7445e-01, 0.0000e+00],\n",
            "          [0.0000e+00, 5.9475e-01, 5.7401e-01,  ..., 1.4463e+00,\n",
            "           7.0291e-01, 0.0000e+00]],\n",
            "\n",
            "         [[3.6209e-03, 1.2981e-01, 0.0000e+00,  ..., 7.8135e-01,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [6.2933e-01, 8.6088e-01, 0.0000e+00,  ..., 2.9871e+00,\n",
            "           1.2012e-01, 0.0000e+00],\n",
            "          [1.1541e-01, 5.3023e-01, 0.0000e+00,  ..., 2.3027e+00,\n",
            "           2.2574e+00, 0.0000e+00],\n",
            "          [1.3627e-02, 5.4174e-01, 0.0000e+00,  ..., 3.8798e+00,\n",
            "           2.4290e+00, 0.0000e+00]],\n",
            "\n",
            "         [[2.7223e+00, 3.2751e+00, 8.2913e-01,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [2.7052e+00, 1.8257e+00, 1.2843e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [2.6213e+00, 3.2044e+00, 2.1156e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [1.0639e+00, 2.5388e+00, 4.0256e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00]]]], grad_fn=<ReluBackward1>)\n",
            "torch.Size([1, 512, 4, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzT9wrddCOmt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PxeqSiVE8pH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}