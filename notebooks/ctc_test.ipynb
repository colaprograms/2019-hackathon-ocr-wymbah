{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ctc-test.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/colaprograms/2019-hackathon-ocr-wymbah/blob/master/notebooks/ctc_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47zAK9Hd86yi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, torch, re, sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as p\n",
        "import random, PIL"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnmS2Npz9SDs",
        "colab_type": "code",
        "outputId": "e89d6ac8-0bff-4a9a-9f20-e5df811354ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "os.chdir(\"/content\")\n",
        "if not os.path.exists(\"/content/AI4Good---Meza-OCR-Challenge\"):\n",
        "  !git clone https://github.com/Charitable-Analytics-International/AI4Good---Meza-OCR-Challenge\n",
        "if not os.path.exists(\"/content/2019-hackathon-ocr-wymbah\"):\n",
        "  !git clone https://github.com/colaprograms/2019-hackathon-ocr-wymbah\n",
        "os.chdir(\"/content/2019-hackathon-ocr-wymbah\")\n",
        "!git pull\n",
        "\n",
        "from importlib import reload\n",
        "import util.file\n",
        "reload(util.file)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "try:\n",
        "  os.mkdir(\"/content/gdrive/My Drive/code\")\n",
        "except:\n",
        "  pass\n",
        "try:\n",
        "  os.mkdir(\"/content/gdrive/My Drive/code/checkpoint\")\n",
        "except:\n",
        "  pass"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already up to date.\n",
            "Using path /content/AI4Good---Meza-OCR-Challenge\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBrQBRzb9Vyp",
        "colab_type": "code",
        "outputId": "089c756f-3935-453b-a274-7f9b291c8783",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        }
      },
      "source": [
        "from util.file import FileHolder\n",
        "fh = FileHolder()\n",
        "inp, outp = fh.get_batch(1)\n",
        "\n",
        "for file, val in zip(inp, outp):\n",
        "  print(val)\n",
        "  p.imshow(file)\n",
        "  p.show()\n",
        "\n",
        "def to_tensor(buf):\n",
        "  buf = 2*buf - 1\n",
        "  return torch.tensor(buf, dtype=torch.float32).permute(0, 3, 1, 2)\n",
        "\n",
        "def get_batch(batchsize, validation=False):\n",
        "  inp, outp = fh.get_batch(batchsize, validation)\n",
        "  inp = np.stack(inp)\n",
        "  inp = to_tensor(inp)\n",
        "  return inp, outp\n",
        "\n",
        "get_batch(20)[0].shape"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB2CAYAAADY3GjsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRQFc4As6AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([20, 3, 64, 256])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLBd53Ar990X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gj9U2jENAnfQ",
        "colab_type": "code",
        "outputId": "36111855-0da4-43b2-ffdd-028b23c2f728",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2060
        }
      },
      "source": [
        "chars = \" 0123456789-,.\"\n",
        "nchars = len(chars)\n",
        "idx = {}\n",
        "for i, c in enumerate(chars): idx[c] = i\n",
        "\n",
        "ntraining = len(fh.info['training'])\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "def maketarget(outputs):\n",
        "  classes = [torch.tensor([idx[c] for c in string], dtype=torch.long) for string in outputs]\n",
        "  lengths = [len(string) for string in outputs]\n",
        "  return nn.utils.rnn.pack_sequence(classes, enforce_sorted=False), lengths\n",
        "\n",
        "trainloss = []\n",
        "validloss = []\n",
        "def run():\n",
        "  resnet = torchvision.models.resnet.resnet34(True)\n",
        "\n",
        "  \"Cut off the last two layers\"\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.maxpool(x)\n",
        "\n",
        "    x = self.layer1(x)\n",
        "    x = self.layer2(x)\n",
        "    #x = self.layer3(x)\n",
        "    #x = self.layer4(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "  import types\n",
        "  resnet.forward = types.MethodType(forward, resnet)\n",
        "  resnet = resnet.cuda()\n",
        "  for param in resnet.parameters():\n",
        "    param.requires_grad = False\n",
        "  lstm1 = nn.LSTM(128, 64, batch_first=True, dropout=0.1, bidirectional=True, num_layers=1).cuda()\n",
        "  down = nn.Conv1d(128, 128, 3, stride=2, padding=1).cuda()\n",
        "  layernorm3 = nn.LayerNorm((128,)).cuda()\n",
        "  lstm2 = nn.LSTM(128, 64, batch_first=True, bidirectional=True).cuda()\n",
        "  layernorm1 = nn.LayerNorm((128,)).cuda()\n",
        "  dense1 = nn.Linear(128, 64).cuda()\n",
        "  layernorm2 = nn.LayerNorm((64,)).cuda()\n",
        "  dense2 = nn.Linear(64, nchars).cuda()\n",
        "  def params():\n",
        "    yield from lstm1.parameters()\n",
        "    yield from lstm2.parameters()\n",
        "    yield from down.parameters()\n",
        "    yield from dense1.parameters()\n",
        "    yield from dense2.parameters()\n",
        "  avgpool = nn.AdaptiveAvgPool2d((1, 32)).cuda()\n",
        "  ctc = nn.CTCLoss(reduction='sum').cuda()\n",
        "  \n",
        "  optimizer = optim.SGD(params(), lr=0.001, momentum=0.9)\n",
        "\n",
        "  def input_to_string(inp):\n",
        "    assert inp.shape[0] == 1\n",
        "    inp = inp.detach().cpu().numpy()\n",
        "    def randchoice(p):\n",
        "      p = np.exp(p)\n",
        "      u = random.random()\n",
        "      for i in range(p.shape[0]):\n",
        "        u -= p[i]\n",
        "        if u < 0:\n",
        "          return i\n",
        "      raise Exception(\"not a probability distribution\")\n",
        "    return \"\".join(chars[randchoice(inp[0, j, :])] for j in range(inp.shape[1]))\n",
        "  def crunch_input(inp):\n",
        "    inp = resnet(inp.cuda())\n",
        "    inp = avgpool(inp)\n",
        "    inp = inp.reshape([-1, 128, 32]).permute(0, 2, 1)\n",
        "    inp, _ = lstm1(inp)\n",
        "    inp = inp.permute(0, 2, 1)\n",
        "    inp = down(inp)\n",
        "    inp = inp.permute(0, 2, 1)\n",
        "    inp = layernorm3(inp)\n",
        "    inp, _ = lstm2(inp)\n",
        "    inp = layernorm1(inp)\n",
        "    #print(inp.shape)\n",
        "    inp = dense1(inp)\n",
        "    #print(inp.shape)\n",
        "    inp = layernorm2(inp)\n",
        "    #print(inp.shape)\n",
        "    inp = dense2(inp)\n",
        "    #print(inp.shape)\n",
        "    inp = nn.functional.log_softmax(inp, dim=2)\n",
        "    return inp\n",
        "  def crunch(inp, outp):\n",
        "    inp = crunch_input(inp)\n",
        "    inp = inp.permute(1, 0, 2)\n",
        "    input_lengths = [16 for i in range(inp.shape[1])]\n",
        "    target, target_lengths = maketarget(outp)\n",
        "    input_lengths, target_lengths = map(tuple, [input_lengths, target_lengths])\n",
        "    #print(inp.shape)\n",
        "    loss = ctc(inp, target.data.cuda(), input_lengths, target_lengths)\n",
        "    return loss\n",
        "  for epoch in range(999999):\n",
        "    running_loss = 0.0\n",
        "    length = 0\n",
        "    print(\"Example output:\")\n",
        "    inp, outp = get_batch(1)\n",
        "    string = input_to_string(crunch_input(inp))\n",
        "    print(string, outp)\n",
        "    for i in range(160):\n",
        "      inp, outp = get_batch(BATCH_SIZE)\n",
        "      optimizer.zero_grad()\n",
        "      loss = crunch(inp, outp)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      running_loss += loss.item()\n",
        "      length += BATCH_SIZE\n",
        "    loss = None\n",
        "    trainingloss = running_loss / length\n",
        "    print(\"Epoch %d. Loss: %f\" % (epoch, trainingloss))\n",
        "    trainloss.append(trainingloss)\n",
        "    running_loss = 0.0\n",
        "    length = 0\n",
        "    with torch.no_grad():\n",
        "      for i in range(20):\n",
        "        inp, outp = get_batch(BATCH_SIZE, validation=True)\n",
        "        loss = crunch(inp, outp)\n",
        "        running_loss += loss.item()\n",
        "        length += BATCH_SIZE\n",
        "    validationloss = running_loss / length\n",
        "    print(\"Validation loss: %f\" % validationloss)\n",
        "    validloss.append(validationloss)\n",
        "    file = \"/content/gdrive/My Drive/code/checkpoint/checkpoint-%04d-%.2f\" % (epoch, validationloss)\n",
        "    torch.save({\n",
        "        'lstm1': lstm1.state_dict(),\n",
        "        'lstm2': lstm2.state_dict(),\n",
        "        'dense1': dense1.state_dict(),\n",
        "        'dense2': dense2.state_dict(),\n",
        "        'down': down.state_dict()\n",
        "    }, file)\n",
        "    print(\"Saved\", file)\n",
        "\n",
        "run()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:54: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Example output:\n",
            "73856757,75,-,34 ['130']\n",
            "Epoch 0. Loss: 569.330618\n",
            "Validation loss: 645.763687\n",
            "Saved /content/gdrive/My Drive/code/checkpoint/checkpoint-0000-645.76\n",
            "Example output:\n",
            "                 ['-114.52']\n",
            "Epoch 1. Loss: 592.027699\n",
            "Validation loss: 477.628728\n",
            "Saved /content/gdrive/My Drive/code/checkpoint/checkpoint-0001-477.63\n",
            "Example output:\n",
            "                 ['190']\n",
            "Epoch 2. Loss: 636.469933\n",
            "Validation loss: 459.942751\n",
            "Saved /content/gdrive/My Drive/code/checkpoint/checkpoint-0002-459.94\n",
            "Example output:\n",
            "                 ['11']\n",
            "Epoch 3. Loss: 569.506088\n",
            "Validation loss: 667.665353\n",
            "Saved /content/gdrive/My Drive/code/checkpoint/checkpoint-0003-667.67\n",
            "Example output:\n",
            "                 ['73']\n",
            "Epoch 4. Loss: 551.958488\n",
            "Validation loss: 550.579997\n",
            "Saved /content/gdrive/My Drive/code/checkpoint/checkpoint-0004-550.58\n",
            "Example output:\n",
            "               , ['250']\n",
            "Epoch 5. Loss: 506.396024\n",
            "Validation loss: 593.989011\n",
            "Saved /content/gdrive/My Drive/code/checkpoint/checkpoint-0005-593.99\n",
            "Example output:\n",
            "                 ['4,00']\n",
            "Epoch 6. Loss: 548.973679\n",
            "Validation loss: 467.609155\n",
            "Saved /content/gdrive/My Drive/code/checkpoint/checkpoint-0006-467.61\n",
            "Example output:\n",
            "               3 ['94']\n",
            "Epoch 7. Loss: 535.622374\n",
            "Validation loss: 425.789328\n",
            "Saved /content/gdrive/My Drive/code/checkpoint/checkpoint-0007-425.79\n",
            "Example output:\n",
            "               2 ['83.5']\n",
            "Epoch 8. Loss: 465.399888\n",
            "Validation loss: 361.695793\n",
            "Saved /content/gdrive/My Drive/code/checkpoint/checkpoint-0008-361.70\n",
            "Example output:\n",
            "              88 ['13']\n",
            "Epoch 9. Loss: 458.126913\n",
            "Validation loss: 361.648027\n",
            "Saved /content/gdrive/My Drive/code/checkpoint/checkpoint-0009-361.65\n",
            "Example output:\n",
            " 222122122222221 ['15']\n",
            "Epoch 10. Loss: 464.993646\n",
            "Validation loss: 772.157037\n",
            "Saved /content/gdrive/My Drive/code/checkpoint/checkpoint-0010-772.16\n",
            "Example output:\n",
            "                 ['10,900']\n",
            "Epoch 11. Loss: 465.127318\n",
            "Validation loss: 448.288347\n",
            "Saved /content/gdrive/My Drive/code/checkpoint/checkpoint-0011-448.29\n",
            "Example output:\n",
            "               2 ['7,8']\n",
            "Epoch 12. Loss: 503.469474\n",
            "Validation loss: 698.162881\n",
            "Saved /content/gdrive/My Drive/code/checkpoint/checkpoint-0012-698.16\n",
            "Example output:\n",
            " 555555555555555 ['1.0']\n",
            "Epoch 13. Loss: 431.506976\n",
            "Validation loss: 530.831552\n",
            "Saved /content/gdrive/My Drive/code/checkpoint/checkpoint-0013-530.83\n",
            "Example output:\n",
            "               0 ['12']\n",
            "Epoch 14. Loss: 443.794977\n",
            "Validation loss: 582.361354\n",
            "Saved /content/gdrive/My Drive/code/checkpoint/checkpoint-0014-582.36\n",
            "Example output:\n",
            "  22222222222223 ['12']\n",
            "Epoch 15. Loss: 523.554923\n",
            "Validation loss: 611.046841\n",
            "Saved /content/gdrive/My Drive/code/checkpoint/checkpoint-0015-611.05\n",
            "Example output:\n",
            " 000000000000000 ['78']\n",
            "Epoch 16. Loss: 521.414940\n",
            "Validation loss: 499.160153\n",
            "Saved /content/gdrive/My Drive/code/checkpoint/checkpoint-0016-499.16\n",
            "Example output:\n",
            "               1 ['135']\n",
            "Epoch 17. Loss: 462.593072\n",
            "Validation loss: 538.374591\n",
            "Saved /content/gdrive/My Drive/code/checkpoint/checkpoint-0017-538.37\n",
            "Example output:\n",
            "               1 ['11.5']\n",
            "Epoch 18. Loss: 468.294186\n",
            "Validation loss: 553.894228\n",
            "Saved /content/gdrive/My Drive/code/checkpoint/checkpoint-0018-553.89\n",
            "Example output:\n",
            "               0 ['140']\n",
            "Epoch 19. Loss: 435.121080\n",
            "Validation loss: 428.384071\n",
            "Saved /content/gdrive/My Drive/code/checkpoint/checkpoint-0019-428.38\n",
            "Example output:\n",
            "               7 ['149']\n",
            "Epoch 20. Loss: 458.746447\n",
            "Validation loss: 705.353235\n",
            "Saved /content/gdrive/My Drive/code/checkpoint/checkpoint-0020-705.35\n",
            "Example output:\n",
            " 000000000000002 ['13']\n",
            "Epoch 21. Loss: 441.048713\n",
            "Validation loss: 335.198952\n",
            "Saved /content/gdrive/My Drive/code/checkpoint/checkpoint-0021-335.20\n",
            "Example output:\n",
            "               0 ['11,7']\n",
            "Epoch 22. Loss: 395.815455\n",
            "Validation loss: 445.212057\n",
            "Saved /content/gdrive/My Drive/code/checkpoint/checkpoint-0022-445.21\n",
            "Example output:\n",
            "               4 ['144']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KXbhC7NAoZF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hj5J3EU6Bkod",
        "colab_type": "code",
        "outputId": "4c8d2fe6-3c70-4aef-fcf6-7e2aebca02c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        }
      },
      "source": [
        "image_tensor = torch.Tensor(image)\n",
        "image_tensor = torch.unsqueeze(image_tensor, 0)\n",
        "image_tensor = image_tensor.permute(0, 3, 1, 2)\n",
        "out = resnet(image_tensor)\n",
        "print(out)\n",
        "print(out.shape)"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[[0.0000e+00, 8.4632e-03, 4.4118e-01,  ..., 3.5947e-01,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [1.5710e+00, 1.6492e+00, 4.3799e-01,  ..., 1.9591e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.5652e+00,\n",
            "           1.0369e-01, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 2.7234e-01,  ..., 4.7540e+00,\n",
            "           1.5719e+00, 0.0000e+00]],\n",
            "\n",
            "         [[8.1148e-01, 6.8881e-01, 1.4770e+00,  ..., 2.5300e+00,\n",
            "           2.8111e-01, 0.0000e+00],\n",
            "          [0.0000e+00, 1.1480e-01, 1.6761e+00,  ..., 3.0082e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 3.6867e-01,  ..., 6.7188e-02,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 7.3576e-01,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00]],\n",
            "\n",
            "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.6493e-01,\n",
            "           6.6963e-01, 1.3038e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 2.3498e-01,  ..., 3.9726e+00,\n",
            "           3.6936e+00, 4.9995e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.2699e+00,\n",
            "           1.9825e+00, 3.4142e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.0000e+00, 0.0000e+00, 8.0649e-01,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 1.9799e-01,  ..., 1.9203e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [8.3722e-01, 6.5913e-01, 0.0000e+00,  ..., 3.8010e+00,\n",
            "           8.7445e-01, 0.0000e+00],\n",
            "          [0.0000e+00, 5.9475e-01, 5.7401e-01,  ..., 1.4463e+00,\n",
            "           7.0291e-01, 0.0000e+00]],\n",
            "\n",
            "         [[3.6209e-03, 1.2981e-01, 0.0000e+00,  ..., 7.8135e-01,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [6.2933e-01, 8.6088e-01, 0.0000e+00,  ..., 2.9871e+00,\n",
            "           1.2012e-01, 0.0000e+00],\n",
            "          [1.1541e-01, 5.3023e-01, 0.0000e+00,  ..., 2.3027e+00,\n",
            "           2.2574e+00, 0.0000e+00],\n",
            "          [1.3627e-02, 5.4174e-01, 0.0000e+00,  ..., 3.8798e+00,\n",
            "           2.4290e+00, 0.0000e+00]],\n",
            "\n",
            "         [[2.7223e+00, 3.2751e+00, 8.2913e-01,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [2.7052e+00, 1.8257e+00, 1.2843e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [2.6213e+00, 3.2044e+00, 2.1156e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [1.0639e+00, 2.5388e+00, 4.0256e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00]]]], grad_fn=<ReluBackward1>)\n",
            "torch.Size([1, 512, 4, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzT9wrddCOmt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PxeqSiVE8pH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}