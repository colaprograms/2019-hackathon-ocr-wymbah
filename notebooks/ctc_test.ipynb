{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ctc-test.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/colaprograms/2019-hackathon-ocr-wymbah/blob/master/notebooks/ctc_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47zAK9Hd86yi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, torch, re, sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as p\n",
        "import random, PIL"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnmS2Npz9SDs",
        "colab_type": "code",
        "outputId": "8f242f84-6d36-4a56-a104-95a21ef6c506",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "os.chdir(\"/content\")\n",
        "if not os.path.exists(\"/content/AI4Good---Meza-OCR-Challenge\"):\n",
        "  !git clone https://github.com/Charitable-Analytics-International/AI4Good---Meza-OCR-Challenge\n",
        "if not os.path.exists(\"/content/2019-hackathon-ocr-wymbah\"):\n",
        "  !git clone https://github.com/colaprograms/2019-hackathon-ocr-wymbah\n",
        "os.chdir(\"/content/2019-hackathon-ocr-wymbah\")\n",
        "!git pull\n",
        "\n",
        "from importlib import reload\n",
        "import util.file\n",
        "reload(util.file)"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects:  11% (1/9)   \u001b[K\rremote: Counting objects:  22% (2/9)   \u001b[K\rremote: Counting objects:  33% (3/9)   \u001b[K\rremote: Counting objects:  44% (4/9)   \u001b[K\rremote: Counting objects:  55% (5/9)   \u001b[K\rremote: Counting objects:  66% (6/9)   \u001b[K\rremote: Counting objects:  77% (7/9)   \u001b[K\rremote: Counting objects:  88% (8/9)   \u001b[K\rremote: Counting objects: 100% (9/9)   \u001b[K\rremote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects:  50% (1/2)   \u001b[K\rremote: Compressing objects: 100% (2/2)   \u001b[K\rremote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 5 (delta 3), reused 5 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects:  20% (1/5)   \rUnpacking objects:  40% (2/5)   \rUnpacking objects:  60% (3/5)   \rUnpacking objects:  80% (4/5)   \rUnpacking objects: 100% (5/5)   \rUnpacking objects: 100% (5/5), done.\n",
            "From https://github.com/colaprograms/2019-hackathon-ocr-wymbah\n",
            "   7061cfc..d925a11  master     -> origin/master\n",
            "Updating 7061cfc..d925a11\n",
            "Fast-forward\n",
            " util/.file.py.swp | Bin \u001b[31m16384\u001b[m -> \u001b[32m16384\u001b[m bytes\n",
            " util/file.py      |   2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 2 files changed, 1 insertion(+), 1 deletion(-)\n",
            "Using path /content/AI4Good---Meza-OCR-Challenge\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'util.file' from '/content/2019-hackathon-ocr-wymbah/util/file.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBrQBRzb9Vyp",
        "colab_type": "code",
        "outputId": "f6a46c6a-2e1c-46e4-9ff0-1a03fdfe13a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        }
      },
      "source": [
        "from util.file import FileHolder\n",
        "fh = FileHolder()\n",
        "inp, outp = fh.get_batch(1)\n",
        "\n",
        "for file, val in zip(inp, outp):\n",
        "  print(val)\n",
        "  p.imshow(file)\n",
        "  p.show()\n",
        "\n",
        "def to_tensor(buf):\n",
        "  buf = 2*buf - 1\n",
        "  return torch.Tensor(buf).permute(0, 3, 1, 2)\n",
        "\n",
        "def get_batch(batchsize, validation=False):\n",
        "  inp, outp = fh.get_batch(batchsize, validation)\n",
        "  inp = np.stack(inp)\n",
        "  inp = to_tensor(inp)\n",
        "  return inp, outp\n",
        "\n",
        "get_batch(20)[0].shape"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "75\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAB2CAYAAADGFVhfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJztnVlsZNl533+n9n3jWiSbvU1LmtEo\nniStxYoeZBsyZMGI8mAIVgJECQTMiw04QIBkhAAJkiflJY6DBIYHiGAZSCw5SAQJghBZGTvKgyBZ\nkj32jGZtdc9MN8nmUqx9X04eWN+ZwztFdnU3ySoWzw8gqurWrbrnHtb9n+9+5zvfp7TWOBwOh2N2\n8U26AQ6Hw+E4XZzQOxwOx4zjhN7hcDhmHCf0DofDMeM4oXc4HI4Zxwm9w+FwzDinIvRKqU8rpV5X\nSt1SSj13GsdwOBwOx3iok46jV0r5gTeATwH3gB8Dn9dav3KiB3I4HA7HWJyGRf8R4JbW+rbWugN8\nDfjsKRzH4XA4HGMQOIXvXAXuWq/vAR/17qSUehZ4FiAej//dD3zgA6fQFMdJ0e126Xa71Ot1fD4f\ngUAApdR79pNtSim01njvGO337Ueboz5z1N3nqO84jofZ33vMs1xJ/rDnJYzbxkf9/lHHGgwGAHQ6\nHXq9HlprwuEwyWQSpRR+v/9Ejuc4zE9/+tM9rfXCg/Y7DaEfC63188DzADdv3tQ/+clPJtUUxxhs\nbGzw1ltv8f3vf59oNEomkyEUCtHv99Fa4/P5zAAQDAbx+Xy0221z0QNmH7/fj9/vJxgMGgGwB4bB\nYGCe+3y+Q0JvvycC4vO9e2OqlDKfkePKoxzH7/cfOjd7QJJ9hMFgYP7k+KM+a7dJ2qC1pt/vH9rf\n+/2jsL/jqP297fC2x+4n+/zkf2AP1vb3e/viuDb3+306nQ79fp9ms0m322Vra4tSqYRSiuvXr/Op\nT32KWCxGKpUiHA4fe96Oh0cp9fY4+52G0G8Al6zXa8NtjnNMMBgkHo+zvLxMLBZjbm6OcDhsBEVE\nyRaQbrdr3od3RdgWGhFpW+iPEt5RojpKDL2fsbcDhwYG7z72fvCuoNrCOeqz3uPI+XgFeRyht/vK\n255R7fW+Zx931GBn/69GCf2othx1rF6vx2AwoN1um0EtEAjQ6XSIxWKEQiEz8Dsmx2kI/Y+BG0qp\nqxwI/G8C//AUjuM4Q0Tkn3nmGRKJBPl8nkgkMnLfk3a1OKYf+V+/8sor3L17l93dXRYWFkgmk+bO\nzTE5TlzotdY9pdRvA98F/MBXtNY/O+njOM4WscBjsRjRaJRgMEgwGJx0sxxTRigUIhwOEw6HjSXv\nBvbJcyo+eq31d4DvnMZ3OyaD3+8nEomQTqcJh8POQnOMJBQKEYvFSCaTRKPRsV1VjtPFOc4cYyGT\nqGKpuYvXMQq/328m5EdN9jomgxN6x9jYUS7u4nWMQiaCj4tUcpw9TugdYyGWmbPQHMcxKrzTMXmc\n0DvGxg7JczhGYQu9bdU7JosTesdD4ax6x3GIyPf7/fcs2nJMjomtjHWcb6btwj2uPW5QmhxO5KcD\nJ/SOsZEl/dMonKPSEExjO2cde/XzUfmOHGePE3rHWIxKTzBNHNU2J/Zni52nxzE9OKF3jIVY8+12\nG601oVAIpZRJXNZsNun1enQ6HeObtZOISXy1nVTMm4/FDsfzRm3YAj4qr4wk1YJ38/JkMhkikcjY\nK3gl82K9XqfZbLK/v0+73TbtlLUE9oRjr9d7T+KyowZCsXQl/0s8HicYDJpFaKFQyBzjvCLtDwQC\nJpeRE/3J44TeMRb2JJstbN1ul3a7Ta1Wo9PpGMG3E53J4hkRskDg4GfnnayT13KMUZN5o7IxKqWo\n1+u0220AIpEI/X7fJNUal36/b1Ixl8tlNjY2aDQa9Ho9AJNx0+4LSeblHZBGib18PhKJEIlEyGQy\nJp2EUurI1M/nCbHm7fUW5/2cZgEn9I6HwrZke70exWKRer3O/fv3qVar7O/v02q1jDgCJqlVOBw+\nVuhF3MVKHpUp0rb+7TznYo1HIhFSqRSXLl0ilUoRiUSOTY9rH3d/f59KpcLt27fZ2dnh5Zdfpl6v\nHxL6QCBwrNB722kjVm4kEiGZTLK8vEwqleL69evkcjkWFhaIRqPE43F8Pt+5zCVku27sUFwn9pPF\nCb1jbGzfq1jttVqNSqXC7u4upVKJ+/fvG+veTmEswmW7brxWui303vTH3oyYttDb7oFsNgswUoCP\nQgYWOY933nmHra0tXn/9dZrNprmDsV034l6y22oz6rjy+VAoRDKZpNFoGPdSp9MhEAjQ6/VMwrjz\nKPRejrvDcZwdTugdY2Hfkkuu+W63y/7+PoVCgdu3b7O7u8udO3coFAo0Gg1j2YuP2yvW3oIjIvR2\nZE8oFDI+fvms7AMYP3A2myUWi3H16lW63S4rKyuHju3FFqBms0m73ebtt9/m7bff5gc/+AH37t3j\nhz/8IZ1Ox8w3iEVvf/647x61Tc45k8mwvr5OLpdDa02xWMTv95s87lrrI9NATzOjXGxO5CePE3rH\nWNgTq3YFpVAoRCQSIRaLEY/HSSQSNJtNAGORd7vd9/jg5X159C6bt48TCASMJS3i3Wq1GAwGZj/x\nx4vFHIvFHljwQgaMRqNBvV5nf3+fvb09CoUClUrl0CARiUSIRqOk0+lDbpXjKk5Jv8k5y4ARCARI\npVLk83my2Sxzc3Nks1kSiYQ5DxlQziPe83dMnvP7a3KcKbbo2uUAk8kkg8GA+fl5fD4frVbLTI76\n/X6azaaZ0Ox2u6b83KjVk/ZxJBWyTF4GAgGzf7fbpVgs0ul0zGei0eihaBbxdx8lmOJ26Xa77O7u\nsr+/zxtvvMGtW7d44403jG9e2pXJZFhYWOB973sf4XCYVCplBjG5A1FKvWfCWrbZA1MkEiGRSLC0\ntEQymTQ++nw+TyKRIJFInFuB9EZNuTUN04ETesdDY/vqI5EIvV6PdDqN1ppGo4HWmnq9TiAQoNls\nGtEUv7k8eiddRQwCgYARaak16vP5jB97MBgcstS11gQCAcLhMLFYzNxdPCidsrShVqtRLpcplUqU\nSiWq1aoJq5QBJ5fLsbS0xOXLl03EjFLKnINX6Hu93qFtzWbzkNBLOcZ4PM7c3BypVIpoNDpTuf5t\noXdMFif0jrEYFdbo9/uZn583ItVoNFhbW6NWq9Fut6nX63Q6HWPN2ha9LfiCHY4Zj8eNW0juDGq1\nGhsbG2xvb9Pv96nVakZILl26xMrKCteuXWN9fZ3l5WVzJzCKwWBgwkG3t7e5e/cud+/eZXt7m0ql\nYtq1tLREJpPhwx/+MNeuXePjH/84oVCIRCKBz+c7ciLWnpfQWh+y/MX1I4ORPB53B3Je8LrhHNPB\n+f5VOc4cO82A3+8nGo0SiUTw+XwkEgni8biZhJVFTFIkXFwaIvSyn120W0QwmUwSDodNbHmlUqFc\nLhu3QCKROOSjT6fTZLNZstks6XTahCg+qLB1t9ulVqtRKpWoVCpmkBLi8Ti5XI7V1VUuX77MjRs3\nCAaDxGKxI/3/o4Rf3E7yWtxS9gS3ywzqOC2c0DvGZlQEhcSVx+NxM2Epvm1b4AEj0t4wSjicFVNi\n7u0KRYVCgVgsRrFYpFwum/2WlpZIJBJ88IMfZH19nRs3bpDNZh9oGfd6PRqNBpVKhZ2dHTY3NykU\nCtRqNTOJLHcsa2trrK+vs7KyQi6XM4PRuCs+bStXXnvjzGcFb7SNy0s/HTihdzwUR+WTsePZ7VQG\nXoHzLpCSuwP7uyQyxRbCVqtFo9Ewi6+kDYlEglwux+LiIsvLy8zNzRGLxcY6D1nVW6/XqdVqtFot\nut3uoQFH6p8mk0lisdgjl8ez5zW85zxrjFrN7JgsTugdj4wtVmJBn9Yin1qtRiAQMK4gibjJ5/Os\nr69z/fp1Ll26xOLi4liWdrfbpVwuUygUKBQK7O3tmYVeMrGbTqdZXV01Pv9sNvtI53cRV4c6cZ8u\nXLYhx7lAfPuScEzSEiSTSebn50kmk2auYBxB7ff7ZoK32WyaeYPBYGCifnK5nPH7JxKJY1MpOI7m\nIg1w04qz6B1Tjbh92u021WrVpFro9XqEw2FWVla4ceMG+XyeVCp1rG/etjI7nQ77+/tsb29TLpep\nVqsmvj8SiZDNZrl+/TrXrl3j6tWrLC4uEo/HT/18ZwVvjWEn9pPFCb1jbCZx0UpYYr1eN2kVJIVA\nLBYzUTbHhVJ6kXkDcQHJMQCTRli+O5VKkUgkHur7HY5p47F+uUqpt4Aq0Ad6WuubSqkc8HXgCvAW\n8DmtdfHxmumYNPYE5VlGizQaDZrNJru7u+zt7VGpVAC4fPkyuVyOK1eusL6+TiaTGcs3L5PAko5Y\nJmElpFIWac3Pz3P16lXW1tbI5/Mm9YHDcR45iV/uL2mtn9Fa3xy+fg54QWt9A3hh+NoxI5z1Lfj+\n/j53797lzp07bG5u0mw2iUajPP300zzzzDMmbYBE4xyH+Pmr1SqlUom9vT12dnYol8vU63WTSmF+\nfp7FxUXy+by5cxjn+x2HUyAclVDOcfachonyWeCrw+dfBf7BKRzDcUGQZGOSaEzS+C4vL7OyskIs\nFhtbgGWRlOTfqVarVCoVk71SVuXKwq9xEqM5DuNCKqeTx3U6auBPlVIa+AOt9fPAktZ6a/j+fWBp\n1AeVUs8CzwKsr68/ZjMcZ8VZXMDik+92u9y5c4fbt2/z5ptv0mq1AEilUjz55JPk83lyudwDc9rY\n39tqtSgWi+zt7XH//n22trYolUrU63UymQypVIrl5WWWlpZYWFgwYv8gvGsF5Lnkzbdz5nvXDcwS\ndhppWSfhRH/yPK7Qf0JrvaGUWgS+p5R6zX5Ta62Hg8B7GA4KzwPcvHnT/RKmnLPML97r9djb26Na\nrbKxscHm5ialUgl4N11wMpk0LptxxVJW47ZaLRNaWavVzApeyTeTSqXMJKykPn4Q3qyNdmESpZRJ\nPXwRUh14a/46sZ88jyX0WuuN4eOOUuobwEeAbaVUXmu9pZTKAzsn0E7HFCATmZKL/rRotVq89tpr\n3L17lx/96EfcvXuXcrlMJpPhxo0bJqXv0tLSQwmmJFIrlUomtPL+/fvU63X6/b7Ja7O2tsbKygrL\ny8tG7B+EZLGUQaPb7ZpBRfIARaNRk+MGZs+aBw4NcNInbm5j8jyy0Cul4oBPa10dPv9V4N8B3wK+\nAHx5+PjNk2ioY7LYaQtO4sK13RsieCIO5XL5UP4ZySbp9/uNYIobxJv3/EH+dFuE7AyL4r+XRVlS\n/7bb7R6aiB2VzgHeLV0osfi28Pv9ftLpNIlEwtSMldW3dnKz8zoXYA/63vw2zqKfDh7Hol8CvjG8\nSAPAf9da/2+l1I+BP1FKfRF4G/jc4zfTMWnssMSTsui9dWEbjQa1Wo07d+7w0ksv8dprr/Hzn/+c\narVKNps1C6QksZhtQYsYP6iilFjZIsy22DebTUqlEvfu3aPb7ZJMJs25is9ZqmXZZQ8l5bFkw7QT\nuUkCNKkiFYlESKfTJronGo2aurHnVejhcC1f20dvZ+10TI5HFnqt9W3gF0ZsLwC/8jiNckwftkU/\nKiPhcW4Ir8VnT9jZqYZbrRa1Wo1CocDOzg7b29uUSiWazaaJY5dSe2I9i2Vu1589rh3HFfSW4ijV\napVwOMzu7q5ppxxLCpLId8ijDBy20EtFrnA4TKPRoNFoEIlEaDabJJNJUwxccu7b6Zof1KfTyCgr\n3ln004Fb6ucYGzs+2naZjPs5mQQtFAp0Oh0zESpuCynp9+qrr/Lmm2+yublp/Ofi95YUxS+++CLx\neNwU6xArWfLQS51ZscjF6hYhBkxFKqmAJaGXu7u7Jp+OnGer1TKFSuzJVmlbo9EwCdcESXUcCASI\nxWJmhW06nSaZTJLP50kmk1y6dIlUKsXS0pJZkSufOS/Y9YBt/7xjOnBC7xgL7635w35WhLrRaFAo\nFGg2m5TLZVqtlrFmd3Z2KBQKvPPOO+zv75uBQL5DJlOr1Srb29umWLednsD2p9t+fFuUpf2BQMAM\nCJL6WFbMyp2GWKMSa1+v10177FTLUrBEkq3J4CWDjVTLknqzyWSSZrNJKpVCa00mkzEW/nkSeJtR\n/nnHdOCE3jEWdqpd24p/kKsE3q3NKmUFZbLz/v37Rsz7/T5bW1sUCgVu3bplBgMRx3Q6bao69ft9\nk4RMKUW32zUTtJFIhGAweChSxnaJSOm+TCbD6uqqSXkgue5l8JCFU3IenU7HtF9SQcC7lqxdTUvO\nWQY28d1XKhV8Ph+lUolIJEKhUCAajbK1tUU8HmdjY4O5uTmuX79OJpNhfX3dVLM6L3l2RtUW8G53\nnD3n49fjmArsGHCvT3yU4HvvAmy/uLhSRPg7nQ6FQoH9/X0qlYqJXpEEY7abRuLR5RijJv68sepS\nzCQUChGNRkkkEszNzZmJ3FarRTAYJBKJkEqlCIVCJlulWPriqxd3jJy/DAT2ZGy73TZuqna7bXLq\nyHvSH6FQiG63ayZjK5UK4XCYVqtFJpMxBcPPi9DD4d+JvHZMlvPz63FMFLl4xc3hvXiPE3r7O/x+\nP6FQiFAoZFwr1WqVWq3G7u4uxWLRTIaGw2HW19fJZrM88cQTzM3NsbCwYEISJW98KBQyLhv7T8RG\nHkW85+fnCQaD9Ho9VlZWzCpcaZcsxIrFYocGJhF1OQe7D+R9iZ+XFAubm5vUajV2dnbY29sz4t/v\n99nf32cwGLC1tYVSit3dXbLZLJVKhbW1tUMROXYFr2nE+/uQts764rDzghN6x9iMyl4pVu1xF7O4\nOcLhMN1ul3g8Tr/fJ51Oo5SiWq3S6/UIhUKEw2Hi8bhZqPTEE08wPz/PtWvXzISlCL1dWzaVShk3\nz6j8NGLRi4/c5/PRarVIJBLGty5CH4/HTbz7KH+zfJfXhWXfXYhFn8vlqNfrbG1tsbm5SbVaJRQK\n0Ww22d/fp91um7uFarUKwM7ODqFQiN3dXbTWLC0tvWdwnDa8rj3ntpkunNA7xkKsNbGkx8nX4vWN\ni7XX7/dNMjLJMQ8H9V8lVFJWwEqGysuXLxsfukTV2G4kmZAdlRJBXssgEIvF6Ha7LC0tHYrCkTsD\ncaNI4fNR33XUOY8KJW00GiZfz97eHq+88gqFQoE33njDhI82m002NjYIBoN0Oh2zEnh1dZXFxUXT\n59PqwrHTWHuteld4ZPJM56/GMbU8jqUm4hmJRA75p0UMxIeeTCZZWloyf/Pz86RSqUMuE2+Rbjuc\n8kFtgAMRlsFBxFkGIzmG3InI+48qWIPBgGQySS6XQyll3DLNZpNEImHuatrtNlpr6vU6pVKJra0t\ngsEgxWKRSCRi5hemjVETsBchp895wgm948zw+XyEw2FTZLtcLpvJTaUU4XDYWOcf+tCHuHr1Kpcu\nXSKRSJBMJt8zGQxHRwMdhXyHiLo9mWz79L2feRwkBcL6+joLCwssLCxQLpdZW1tjf3+fl156iZ2d\nHe7du0etVjOpFwaDAcVikeXlZbrdrok+mmZkgJSB11nz04ETeseZYd/aSw4YW1TF555MJllcXGRl\nZYX5+XnC4TCRSOREjm8/nlWyLRngkskk0WjULJ7SWpNMJtne3jYZO5vNponVv3//PslkkmKxSCaT\nodPpnEl7HwevNe+EfjpwQu8Ym1GTsQ+DTFZ2Oh0qlYqJRCmXy6ZyVCwW49KlSywtLR2KODnPSMSP\nTFwnEgkzMR0MBllbW8Pv91Ov180cxGAwMIVRisUi2WzWlDucZkTknX9+unBC7xiLUdEUD4u9QlZW\nmYpvWsIbJQWAHTd/3oVi1JyCpEXudDokk0kajQapVIput0upVKLdbtNoNEzaBUnJcF44ysXmmAxO\n6B1jIZaa7XsdF4k+6Xa7NJtNU+Fpd3eX7e1tOp0OPp+P+fl58vk873//+5mbm5sJax4Ou6xE/OLx\nuMlpk8/nCQQCFItFs3JWFmE1Gg2KxSKFQsFEJ00zttvmvCZnm0Wc0DvGQsTqUax6WQUqud53dnbY\n3d1ld3eXvb09fD4f0WiU1dVVrly5wpNPPmmKdMwK3gneYDBoUi0sLy8TDAbZ2dmh3++zublpsmG2\nWi329/dJJBLnRuidu2b6cELveCge9SK289k3m01arZZZKCShg1IeUGLsZ1ksJPJHVgDbi728WTcl\nh44kUBOmuX+c2E8XTugdY/M4ceRi0TcaDUqlErVaDa01wWCQxcVFUqmUKSoyTjz8ecOOxQdMRkvg\nkMjbC8Hkc95CHqNCQB2O43C/FsepY4uVVHiSUEG/32+ySUr44SyLmC343jTJoyJVXAEPx0ngLHrH\nWJzEbbhd4UkpRSaTIR6Ps76+zuLiIsvLy0Sj0Zm85bdzAnlz5DSbTSqVCrVajUajwWAwIBAIkMlk\nzAT1ysoKiURi6lebequHuQFqOnBC7zhT5KKXFbCy2jOTyZiskbPKKIGW6BqZt+h0OmaVrqwrSKfT\npFIps3J42oXe3YVMH07oHaeOnfBK0gDHYjGTayafzzM3N2cKfZxnxIq1H715c+zC4o1Gg52dHba2\ntkwpxXa7bfplbW3NpIKQurnTzKjMldM8MF0UnNA7zgQRO0kFABzK+z6tWRkfFm8BcnFTycpYWRks\nj/V6nXK5TKlUolwuU61WzeKxVCpFJpMhl8uRy+UIh8OTPr2xcKtjp4/ZuLocU41c+BJCKQuEstks\nkUjkUM3Xs2KUa+G4alnCUZaqvShMQkglDt7n85kyiHZRdFkZfOfOHd566y02NzepVCr0+32SySSX\nL1/mypUrXL9+ndXVVVKp1Cn2yMngRH46cULvOHXkYrfTEIvwSzjhWSPx6RL2KRFB8p53EBABk+gY\nb957iXMXP7uIebPZBDBJ2aS4udSTrdVqbG9vs7+/byKRJOlZNps1tXInMRg+Ct4IK7mjmXaX06wz\n/b8cx7nHtvCkgtSopfJnSb/fp1ar0el0TG6ZVqtlBErcLiL0knpXFnfF4/FDK3drtRrtdptSqUSr\n1aJYLNJut6lUKiaKRoS/VCrR7XZptVq0Wi1u375NsVg06wrm5ubI5/M88cQTrK6usrCwQCaTORcr\nhe1cRtKng8HAhJA6JsMDhV4p9RXg14EdrfXTw2054OvAFeAt4HNa66I6MHF+D/gM0AD+idb6L0+n\n6Y7zgjct8DRYpmJ1iuA2Gg3q9bopAyg+dLHuRajsVbz2AFWpVGi32xSLRRqNhplULZfLRujkWOVy\n2RxbLPtut2uibLLZLLlcjvn5eZPBc5ajkRynzzhX3B8C/xn4I2vbc8ALWusvK6WeG77+l8CvATeG\nfx8Ffn/46HBMHSL2IvS2OIv7xRZ7u6hGJBJBKWXekyycUhpQ7hKq1aqx1AEj9lK/VlxYmUyGlZUV\nstksTz31FKurqzz99NMmi+d5QSKrZO5FBinnupksDxR6rfX/U0pd8Wz+LPDJ4fOvAv+XA6H/LPBH\n+uB+94dKqYxSKq+13jqpBjscJ4UdIdPpdIzgVyoVWq2WEWtJPWCLvaQvGCX08tlOp2OEXkRdXEMS\nfSQF0UXs5+fnWV5eNmUUJS3CecHOcmqv/HUTspPlUX9BS5Z43weWhs9XgbvWfveG294j9EqpZ4Fn\nAdbX1x+xGQ7Ho+H3+0kkEoRCIQaDAel0mng8TqPRIJ1OG7EWt4oIvp0TXqJspP4tQDKZNO6dfr9v\n6sSKdSsWfCKRYGlpiVgsZhZDLS8vk0wmTYSN1JM9T9awDJzdbpder0e/3zfzM47J8dimgtZaK6Ue\neumb1vp54HmAmzdvuqVzjjNFBFfquUqOnWazSSAQoNVqEQqFqNfrZuWq5OmxI0v8fr9ZACURRJKR\nUyYmJbwyHo8TDAaJx+OkUinW1tZIJpPGDy/hpul0mnA4fC5rrkoCOxF5ee2YLI8q9NviklFK5YGd\n4fYN4JK139pwm8MxVcjkqvjP+/0+sViMTqdDNps1ce6NRoNer0ez2TT+dRFwe/GTvLZDNAEzkStC\nb6djzufzJsWBuG8khPO8Iit/RehdCoTp4FGF/lvAF4AvDx+/aW3/baXU1ziYhC07/7xj2hG3gm1F\ni1WeTCZHRuKIkNkCb1uvtriJ0EssvLhxbIH3pieeJWbxnM4b44RX/jEHE6/zSql7wL/hQOD/RCn1\nReBt4HPD3b/DQWjlLQ7CK//pKbTZMQFGWWWzcAHLQi7A+NlHIZOuYqXKo1fgBRk8xD99UUMkz5vr\naVYZJ+rm80e89Ssj9tXAbz1uoxzTiQjcRZ1ck4lRb6oEGQS8+8rfrFrqo7CLpIy6u3FMhvMTt+WY\nKPYCI7/fb0reXRTsRV/id4fxROwiWbV2uKrc7TihnzxO6B1jIX7qarVKMBgkGo0SCARGJvfyPrfL\n59mMY+l63/cey1tH9aTTKhznsjoqv7w8SnSOtEvaNGuib6dl7nQ6tNttms2mybEPXDjDYNpwQu8Y\nC7HUJCujWLYiYF6Bs5+PEt/j8pXblZiOK4YtAmP7x+02nRSPMj9hh2DK/nJes4i9+Ez+ut0unU4H\nv9/vQiwnjBN6x1iI9SwZFmXi0i7k7c34KBe3nflRsCcrR4m6fVxhlKXuFVP5nuMGiHHO1X7+sN9l\nD3ReP/U4KZAfh0m4SWRSWv4PsnI4EAg4t82U4ITeMRZ24ZBgMGiW5otQi7XqdaPIdjs/uXyfvb/9\n+VF53uUz9mft596/k7CeR6Uqth+P6ys5fxncjvrsaVn5DxpYRh1zVNuO+l4vcmcVDodJpVIMBgMy\nmQyxWMysD3BMDif0jrGQzI3pdNo8FyE/KuJkVD53eHcA8C6oGSWGtmvGft9eNWoPIvbdhfe7HgZv\nYZJxRd7ugwel5vWe10nhbfuo/w+8d87Efm/U546LohF3TTKZJBgMsrS0RCqVIpfLOZGfApzQO8ZC\nxFQm1bzWuc1RQm/v5w1V9H52lBh537PfH/Xe4wjoUef0sJPHo3jcQWhcxhmcxn3vuMHOjkKyDQDJ\n8Dmr8xLnCSf0jrEQkX/cqJZxhdhrvR8lNKcZzXKSbqCjvv80sMX1YVw3x73/oO8Lh8NorQmFQmaA\nd1krpwcn9I6xsN0kJ/mdj7v/BDivAAAEeUlEQVTPWQjwaQwgp8Wk2i6/i4u4+vc84JxnDofDMeM4\noXc4HI4Zxwm9w+FwzDhqGhY0KKWqwOuTbscUMA/sTboRE8b1wQGuH1wfwIP74LLWeuFBXzItk7Gv\na61vTroRk0Yp9ZOL3g+uDw5w/eD6AE6uD5zrxuFwOGYcJ/QOh8Mx40yL0D8/6QZMCa4fXB8Irh9c\nH8AJ9cFUTMY6HA6H4/SYFove4XA4HKeEE3qHw+GYcSYu9EqpTyulXldK3VJKPTfp9pwWSqmvKKV2\nlFIvW9tySqnvKaXeHD5mh9uVUuo/Dfvkb5RSf2dyLT85lFKXlFJ/rpR6RSn1M6XU7wy3X7R+iCil\n/kIp9dfDfvi3w+1XlVI/Gp7v15VSoeH28PD1reH7VybZ/pNEKeVXSv2VUurbw9cXsQ/eUkq9pJR6\nUSn1k+G2E70mJir0Sik/8F+AXwOeAj6vlHpqkm06Rf4Q+LRn23PAC1rrG8ALw9dw0B83hn/PAr9/\nRm08bXrAP9daPwV8DPit4f/7ovVDG/hlrfUvAM8An1ZKfQz498Dvaq2fAIrAF4f7fxEoDrf/7nC/\nWeF3gFet1xexDwB+SWv9jBUzf7LXxKgiBWf1B/wi8F3r9ZeAL02yTad8vleAl63XrwP54fM8BwvH\nAP4A+Pyo/WbpD/gm8KmL3A9ADPhL4KMcrIAMDLebawP4LvCLw+eB4X5q0m0/gXNfG4rYLwPfBtRF\n64Ph+bwFzHu2neg1MWnXzSpw13p9b7jtorCktd4aPr8PLA2fz3y/DG+9/zbwIy5gPwxdFi8CO8D3\ngJ8DJa11b7iLfa6mH4bvl4G5s23xqfAfgX8BSOXwOS5eHwBo4E+VUj9VSj073Hai18S0pEC48Git\ntVLqQsS6KqUSwP8E/pnWumLnOL8o/aC17gPPKKUywDeAD0y4SWeKUurXgR2t9U+VUp+cdHsmzCe0\n1htKqUXge0qp1+w3T+KamLRFvwFcsl6vDbddFLaVUnmA4ePOcPvM9otSKsiByP83rfX/Gm6+cP0g\naK1LwJ9z4KbIKKXE+LLP1fTD8P00UDjjpp40fw/4+0qpt4CvceC++T0uVh8AoLXeGD7ucDDof4QT\nviYmLfQ/Bm4MZ9pDwG8C35pwm86SbwFfGD7/Agc+a9n+j4cz7B8DytZt3LlFHZju/xV4VWv9H6y3\nLlo/LAwteZRSUQ7mKV7lQPB/Y7ibtx+kf34D+DM9dNCeV7TWX9Jar2mtr3Bw3f+Z1vofcYH6AEAp\nFVdKJeU58KvAy5z0NTEFExGfAd7gwEf5rybdnlM8zz8GtoAuB361L3LgY3wBeBP4P0BuuK/iIBrp\n58BLwM1Jt/+E+uATHPgj/wZ4cfj3mQvYD38L+KthP7wM/Ovh9mvAXwC3gP8BhIfbI8PXt4bvX5v0\nOZxwf3wS+PZF7IPh+f718O9nooEnfU24FAgOh8Mx40zadeNwOByOU8YJvcPhcMw4TugdDodjxnFC\n73A4HDOOE3qHw+GYcZzQOxwOx4zjhN7hcDhmnP8PrZuj4ftJuCEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([20, 3, 128, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLBd53Ar990X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2397
        },
        "outputId": "fe7a4577-9143-4146-efc2-20f518578690"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "\n",
        "resnet = torchvision.models.resnet.resnet34(True)\n",
        "\n",
        "\"Cut off the last two layers\"\n",
        "def forward(self, x):\n",
        "  x = self.conv1(x)\n",
        "  x = self.bn1(x)\n",
        "  x = self.relu(x)\n",
        "  x = self.maxpool(x)\n",
        "\n",
        "  x = self.layer1(x)\n",
        "  x = self.layer2(x)\n",
        "  x = self.layer3(x)\n",
        "  x = self.layer4(x)\n",
        "\n",
        "  return x\n",
        "\n",
        "import types\n",
        "resnet.forward = types.MethodType(forward, resnet)\n",
        "resnet.cuda()"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (3): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (3): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (4): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (5): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gj9U2jENAnfQ",
        "colab_type": "code",
        "outputId": "b35b7bbf-6d6b-4e56-a1de-9844c31abb39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "source": [
        "chars = \"0123456789-,.\"\n",
        "nchars = len(chars)\n",
        "idx = {}\n",
        "for i, c in enumerate(chars): idx[c] = i\n",
        "\n",
        "ntraining = len(fh.info['training'])\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "lstm = nn.LSTM(128, 128, bidirectional=True)\n",
        "dense = nn.Linear(128, nchars)\n",
        "net = nn.Sequential(\n",
        "    lstm,\n",
        "    dense\n",
        ")\n",
        "net.cuda()\n",
        "\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=9)\n",
        "\n",
        "for epoch in range(20):\n",
        "  running_loss = 0.0\n",
        "  for i in range(int(ntraining / BATCH_SIZE)):\n",
        "    inp, outp = get_batch(BATCH_SIZE)\n",
        "    inp = resnet(inp)\n",
        "    print(inp.shape)\n",
        "    optimizer.zero_grad()\n",
        "    probs = lstm(inputs)\n",
        "    loss = ctc(probs, target, input_lengths, target_lengths, reduction='None')\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-130-e3de5e59484f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mdense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m )\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \"\"\"\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNNBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0;31m# Tensors stored in modules are graph leaves, and we don't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;31m# want to create copy nodes, so we have to unpack the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \"\"\"\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KXbhC7NAoZF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hj5J3EU6Bkod",
        "colab_type": "code",
        "outputId": "4c8d2fe6-3c70-4aef-fcf6-7e2aebca02c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        }
      },
      "source": [
        "image_tensor = torch.Tensor(image)\n",
        "image_tensor = torch.unsqueeze(image_tensor, 0)\n",
        "image_tensor = image_tensor.permute(0, 3, 1, 2)\n",
        "out = resnet(image_tensor)\n",
        "print(out)\n",
        "print(out.shape)"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[[0.0000e+00, 8.4632e-03, 4.4118e-01,  ..., 3.5947e-01,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [1.5710e+00, 1.6492e+00, 4.3799e-01,  ..., 1.9591e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.5652e+00,\n",
            "           1.0369e-01, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 2.7234e-01,  ..., 4.7540e+00,\n",
            "           1.5719e+00, 0.0000e+00]],\n",
            "\n",
            "         [[8.1148e-01, 6.8881e-01, 1.4770e+00,  ..., 2.5300e+00,\n",
            "           2.8111e-01, 0.0000e+00],\n",
            "          [0.0000e+00, 1.1480e-01, 1.6761e+00,  ..., 3.0082e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 3.6867e-01,  ..., 6.7188e-02,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 7.3576e-01,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00]],\n",
            "\n",
            "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.6493e-01,\n",
            "           6.6963e-01, 1.3038e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 2.3498e-01,  ..., 3.9726e+00,\n",
            "           3.6936e+00, 4.9995e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.2699e+00,\n",
            "           1.9825e+00, 3.4142e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.0000e+00, 0.0000e+00, 8.0649e-01,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 1.9799e-01,  ..., 1.9203e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [8.3722e-01, 6.5913e-01, 0.0000e+00,  ..., 3.8010e+00,\n",
            "           8.7445e-01, 0.0000e+00],\n",
            "          [0.0000e+00, 5.9475e-01, 5.7401e-01,  ..., 1.4463e+00,\n",
            "           7.0291e-01, 0.0000e+00]],\n",
            "\n",
            "         [[3.6209e-03, 1.2981e-01, 0.0000e+00,  ..., 7.8135e-01,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [6.2933e-01, 8.6088e-01, 0.0000e+00,  ..., 2.9871e+00,\n",
            "           1.2012e-01, 0.0000e+00],\n",
            "          [1.1541e-01, 5.3023e-01, 0.0000e+00,  ..., 2.3027e+00,\n",
            "           2.2574e+00, 0.0000e+00],\n",
            "          [1.3627e-02, 5.4174e-01, 0.0000e+00,  ..., 3.8798e+00,\n",
            "           2.4290e+00, 0.0000e+00]],\n",
            "\n",
            "         [[2.7223e+00, 3.2751e+00, 8.2913e-01,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [2.7052e+00, 1.8257e+00, 1.2843e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [2.6213e+00, 3.2044e+00, 2.1156e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [1.0639e+00, 2.5388e+00, 4.0256e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00]]]], grad_fn=<ReluBackward1>)\n",
            "torch.Size([1, 512, 4, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzT9wrddCOmt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PxeqSiVE8pH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}